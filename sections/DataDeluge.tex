\block{\begin{blockbody}\section{Why do we need bioimage analysis?}
	\tfont
    We tend to judge data volumes based on their size on a hard drive, but it is worth considering what a typical image actually represents - a numerical matrix with millions of entries, all of which cannot possibly be interrogated manually:\par
     \begin{minipage}{0.72\textwidth}
	\includegraphics[height=0.07\textheight]{DAPIActin} \hfill \includegraphics[height=0.07\textheight]{ImageMatrix} \par
    \end{minipage}\hfill
    \begin{minipage}[c][0.25\textwidth][c]{0.23\textwidth}
    	\setlength{\unitlength}{0.9\textwidth}
    	\input{tex_files/ImageSize}\par
    \end{minipage} \par
    	Experiments can entail hundreds of such exposures of potentially millions of cells. Manual analysis is laborious and time-consuming and effectively places an upper limit on the volume of data that can be \lq\lq processed''. This, in turn, places severe limitations on the scale of experiments that can be conducted, thus limiting scientific advancement.\par
    	{\centering\input{tex_files/DataStorage}}\par
    	There is also a strong economic argument for bioimage analysis. A typical 1PB server costs approximately \textsterling 100K and consumes \textasciitilde 10kW, which equates to \textasciitilde\textsterling 10K per annum. Reliance on manual analysis is therefore not cost-effective, as most of the data stored will never be analysed. Automated analysis is essential to unleash the full scientific potential of modern microscopy. There is a growing acceptance of this need in the community. For example, in their recent strategic review of bioimaging \citep{bbsrc2018}, the BBSRC concluded that:\par
        \centering\fcolorbox{dblue}{lblue}{\parbox{0.85\textwidth}{\color{dblue}\lq\lq Data skills and training are required across the biosciences community to enable high-quality quantitative bioimaging. This includes theoretical understanding of image analysis as well as practical skills and expertise.''}}\par
\end{blockbody}}